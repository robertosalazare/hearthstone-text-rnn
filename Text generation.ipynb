{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM para generar cartas de hearthstone\n",
    "\n",
    "En esta libreta se encuentra la implementación de redes recurrentes lstm con keras, en esta se resuelve el problema de generación de texto a nivel caracter para generar cartas de hearthstone. Este código está basado en la siguiente [entrada](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/) de blog escrita por Jason Brownle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset a utilizar\n",
    "\n",
    "Para esta entrada nos interesa entrenar con todas las cartas de hearthstone existentes, para ello nuestros amigos de [HeathSim](https://hearthsim.info/) se tomaron la molestia de crear un archivo json que contiene todas las cartas en todos los idiomas. Para descargarse se puede hacer desde [este enlace](https://hearthstonejson.com/), en este tutorial estaremos usando las cartas en español, pero se puede, utilizar el json del lenguaje que sea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La implementación\n",
    "\n",
    "Ahora nos centraremos en como se implementan las LSTM con keras, para ello primero que nada se necesitan importar los siguientes módulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora leemos el archivo cards.json previamente descargado con la librería json de la librería estandar de python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cards.json', encoding=\"utf8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez leido el json tenemos que limpiar un poco los textos de las descripciones de las cartas. Para ello se define la lista de caracteres que se quiere remover y se reemplazan con una cadena vacía cada uno. También se pegan los textos de todas las cartas en un string muy largo para trabajar sobre este.\n",
    "\n",
    "El arreglo char_to_in es un diccionario que asigna un número a cada caracter posible, este será utilizado más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_chars = [\"@\", \",\", \".\", \"$\", \":\", \"\\n\", \"!\", \"#\", \"\"\"'\"\"\", \";\", \"?\", \"[\", \"]\", \"{\", \"}\", \"|\", \"\\xa0\", \"¡\", '«', '»', \"¿\", \"…\"]\n",
    "\n",
    "raw_text = \"\" \n",
    "for card in data:\n",
    "    if(\"text\" in card and len(card[\"text\"]) > 1):\n",
    "        text = card[\"text\"]\n",
    "        for char in remove_chars:\n",
    "            text = text.replace(char,\"\")\n",
    "        soup = BeautifulSoup(text)\n",
    "        text = soup.get_text()\n",
    "        if(len(text) > 1):\n",
    "            raw_text = raw_text + \" \" + text\n",
    "\n",
    "chars = sorted(list(set(raw_text))) # Arreglo de todos los posibles caracteres contenidos en todas las cartas.\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después se calculan el número de caracteres total en el texto y el vocabulario total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Número total de caracteres: \", n_chars)\n",
    "print(\"Vocabulario total: \", n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se generan secuencias de caracteres con longitud de 40, se escogió el 40 porque es la longitud promedio de las cadenas de caracteres de los textos de las cartas. Esta longitud es la profundidad que tendrá la red LSTM para hacer el back propagation a través del tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "dataX = [] # \"conjunto de entrenamiento\"\n",
    "dataY = [] # \"Caracter que sigue despues de los 40\"\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Patrones totales: \", n_patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se le aplica un reshape a dataX para que tenga la forma adecuada para el entrenamiento. También se utiliza el método to_categorical de np_utils para transformar las y a one hot(dummy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se define el modelo que se utilizará para entrenar la red, básicamente es una red neuronal secuencial con dos capas LSTM, ambas con dropout de 0.2. Activación softmax para la salida y como optimizador el método de adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guardan los checkpoints en la carpeta checkpoints en la raíz del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"./checkpoints/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena el modelo, la red fue entrenada originalmente por 150 epochs, con un tamaño de batch de 128 y en un GPU NVIDIA geforce gtx 960 de 4gb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar cartas con el modelo ya entrenado\n",
    "\n",
    "Primero se carga el checkpoint guardado anteriormente durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./checkpoints/weights-improvement-150-0.4161.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define este diccionario para transformar la salida a caracter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toma una semilla de dataX y apartir de ella se generan 1000 caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semilla:\n",
      "\" nio 22 Añade El Segundo Sello a tu mano  \"\n",
      "Invoca a un esbirro aleatorio de coste 6 xGl final de tu turnorestaura 4 p de saluda tu héroe xCoito de batalla Invoca a un esbirro aleatorio de coste 6 xGl final de tu turnorestaura 4 p de saluda tu héroe xCoito de batalla Invoca a un esbirro aleatorio de coste 6 xGl final de tu turnorestaura 4 p de saluda tu héroe xCoito de batalla Invoca a un esbirro aleatorio de coste 6 xGl final de tu turnorestaura 4 p de saluda tu héroe xCoito de batalla Invoca a un esbirro aleatorio de coste 6 xGl final de tu turnorestaura 4 p de saluda tu héroe xCoito de batalla Invoca a un esbirro aleatorio de coste 6 xGl final de tu turnorestaura 4 p de saluda tu héroe xCoito de batalla Invoca a un esbirro aleatorio de coste 6 xGl final de tu turnorestaura 4 p de saluda tu héroe xCoito de batalla Invoca a un esbirro aleatorio de coste 6 xGl final de tu turnorestaura 4 p de saluda tu héroe xCoito de batalla Invoca a un esbirro aleatorio de coste 6 xGl final de tu turnorestaura 4 p de saluda tu héroe xCoito de \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Semilla:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
